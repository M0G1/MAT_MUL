# MAT_MUL

Перемножение матриц.
Задача: реализовать алгоритм перемножения матриц.


# Аппаратные компоненты
Для реализации данной задачи использовалась следующая аппаратная база:
Центральный процессор:	11th Gen Intel(R) Core(TM) i5-11400H @ 2.70GHz, 2688 МГц, ядер: 6, логических процессоров: 12  
![image](https://user-images.githubusercontent.com/44916652/155966922-af0831c8-742b-4c7c-8737-0a6beb4bee03.png)  
Тип	Компьютер на базе x64  
Оперативная память:  8 Гб, 800МГц  
![image](https://user-images.githubusercontent.com/44916652/155967126-442203d3-9176-49c2-8c69-7632a2157683.png)  
Графический процессор: NVIDIA GeFOrce RTX 3050 Laptop GPU, 4 Гб видеопамяти, GDDR6
![image](https://user-images.githubusercontent.com/44916652/155966966-9427e479-554d-4af6-9a34-6d53619ed24a.png)  

Функция generateRandMatrix заполняет выделенную память под развертку матрицы в одномерный массив случаныйми числами с двойной точностью.
Функция matrixMultCPU  осуществляет матричные вычисления в памяти центрального процессора. 
Для проверки правильности умножения используется функция checkMult. Её задача состоит в сравнении результатов двух функций.  
В функции matrixMult 1 элемент итоговой матрицы вычисляется на одной нити. Все индексы, необходимые для вычислений, определяются по индексам блока и нити. У этого подхода имеется определённый недостаток. Элементы крупных матриц загружаются несколько раз, находясь при этом в глобальной памяти, что заставляет алгоритм тратить время на повторное обращение к данными в памяти.
Реализация matrixMult основана на скалярном умножении вектора строки и столбца матрицы.
  
  
Вычисления проводились при размере блока: 16
Результаты приведены в таблице:

N | 128 (2^7) | 256 (2^8) | 512 (2^9) | 1024 (2^10) | 2048 (2^11)  
 :---: |  :---: |  :---: |  :---: |  :---: |  :---:   
cpu (s) | 7.734 | 16 | 63.084 | 747.419 | 8116.745 | 173000  
gpu (s) | 0.154 | 1.058 | 7.969 | 320.933 | 728.91  
acceleration | 50.353 | 59.601 | 93.794 | 25.291 | 237.341  

Использование конвеерного процессора для работы с матрицами во много раз более оправданее, из-за квадратичного роста размера данных. Как видно, что при любых выбранных размерах ускорение имеет внушительные значения.
Для матриц с размерностью стороны 1024 наблюдается более низкий коэффициент ускорения. Причиной тому единократный запуск вычислений без проведения усреднения, а также вмешательство других программ, которые используют gpu.
